import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langchain.agents.middleware import LLMToolSelectorMiddleware
from langchain_core.tools import tool
from langchain.messages import HumanMessage, AIMessage, SystemMessage
import datetime
from langchain_community.tools import DuckDuckGoSearchResults
from langchain_community.utilities import DuckDuckGoSearchAPIWrapper
from dotenv import load_dotenv
import os


# .envì—ì„œ OPENAI_API_KEY ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
api_key = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY"))
# api_key = os.getenv("OPENAI_API_KEY")

# -------------------------------
# 1ï¸âƒ£ ê°„ë‹¨í•œ ë„êµ¬ ì •ì˜
# -------------------------------

# # -------------------------------
# # 1ï¸âƒ£ ë„êµ¬ ì •ì˜
# # -------------------------------
# @tool
# def get_current_time(timezone: str, location: str) -> str:
#     """í˜„ì¬ ì‹œê°„ì„ ì§€ì •ëœ íƒ€ì„ì¡´ê³¼ ìœ„ì¹˜ì— ë§ê²Œ ë°˜í™˜í•©ë‹ˆë‹¤."""
#     import pytz
#     from datetime import datetime
#     try:
#         tz = pytz.timezone(timezone)
#         now = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")
#         return f'{timezone} ({location}) í˜„ì¬ì‹œê° {now}'
#     except pytz.UnknownTimeZoneError:
#         return f"ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì„ì¡´: {timezone}"

# @tool
# def get_web_search(query: str, search_period: str) -> str:
#     """DuckDuckGo APIë¥¼ ì´ìš©í•´ ì§€ì •ëœ ê¸°ê°„ ë‚´ì˜ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ì—¬ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
#     wrapper = DuckDuckGoSearchAPIWrapper(region="kr-kr", time=search_period)
#     search = DuckDuckGoSearchResults(api_wrapper=wrapper, source="news", results_separator=';\n')
#     return search.invoke(query)

# def get_current_time(query: str = "") -> str:
#     """í˜„ì¬ ì‹œê°„ì„ ë°˜í™˜í•˜ëŠ” ë„êµ¬"""
#     now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
#     return f"í˜„ì¬ ì‹œê°„ì€ {now} ì…ë‹ˆë‹¤."

# def get_web_search(query: str) -> str:
#     """ê°€ì§œ ì›¹ ê²€ìƒ‰ ì˜ˆì‹œ (ì‹¤ì œ ê²€ìƒ‰ì€ ì•„ë‹˜)"""
#     return f"'{query}'ì— ëŒ€í•œ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# LangChainì˜ Tool ê°ì²´ë¡œ ë“±ë¡
#tools = [get_current_time, get_web_search]

# -------------------------------
# 2ï¸âƒ£ LLM ì´ˆê¸°í™”
# -------------------------------
llm = ChatOpenAI(
    model="gpt-4o-mini",   # ë˜ëŠ” gpt-4o, gpt-3.5-turbo ë“±
    temperature=0.4,
)

# -------------------------------
# 3ï¸âƒ£ Agent ìƒì„±
# -------------------------------
agent = create_agent(
    model=llm,
#    tools=tools,
#    middleware=[LLMToolSelectorMiddleware(max_tools=2)],
)

# -------------------------------
# 4ï¸âƒ£ Streamlit UI ì„¤ì •
# -------------------------------
st.set_page_config(page_title="LangChain Chatbot", page_icon="ğŸ¤–")
st.title("ğŸ¤– LangChain create_agent() Chatbot")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        SystemMessage(content="ì €ëŠ” ê³ ì„±êµ°ì²­ ì§ì›ì„ ìœ„í•´ ìµœì„ ì„ ë‹¤í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ë„ìš°ë¯¸ì…ë‹ˆë‹¤."),
        AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š"),
    ]

# ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
for msg in st.session_state["messages"]:
    if isinstance(msg, SystemMessage):
        st.chat_message("system").write(msg.content)
    elif isinstance(msg, HumanMessage):
        st.chat_message("user").write(msg.content)
    elif isinstance(msg, AIMessage):
        st.chat_message("assistant").write(msg.content)

# -------------------------------
# 5ï¸âƒ£ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
# -------------------------------
if prompt := st.chat_input("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
    st.chat_message("user").write(prompt)
    st.session_state["messages"].append(HumanMessage(content=prompt))

    # Agent í˜¸ì¶œ
    # response = agent.invoke({
    #     "messages": [HumanMessage(content=prompt)]
    # })
    for chunk in agent.stream({"messages": prompt}, stream_mode="values"):
        if "messages" in chunk and chunk["messages"]:
            response = chunk["messages"][-1]
            st.write(response)
 #           st.write(type(response))
#
    # ì‘ë‹µ ë‚´ìš© ì¶”ì¶œ
    if isinstance(response, dict) and "messages" in response:
        msg = response["messages"][-1]
        st.write(msg)
        content = msg.content if hasattr(msg, "content") else str(msg)
        st.write(content)
    else:
        content = str(response)

    st.chat_message("assistant").write(msg[AIMessage.content][-1])

    # AI ì‘ë‹µ ì¶œë ¥
    # st.chat_message("assistant").write(f"message:{ai_reply['messages'][-1].content}")
    # st.session_state["messages"].append(AIMessage(content=ai_reply))
    #st.chat_message("assistant").write(response['messages'][-1].content)
    st.session_state["messages"].append(AIMessage(content))
    #(f"Response: {result1['messages'][-1].content}")






# def get_ai_response(messages):
#     try:
#         response = agent.stream({"messages":messages})
#         response = {"message": messages}
#         gathered = None
#         for chunk in agent.stream(response, stream_mode="updates"):
#             yield chunk
#             if gathered is None:
#                 gathered = chunk
#             else:
#                 gathered += chunk

#         if gathered and getattr(gathered, "tool_calls", None):
#             st.session_state.messages.append(gathered)
#             for tool_call in gathered.tool_calls:
#                 selected_tool = tool_dict.get(tool_call['name'])
#                 if selected_tool:
#                     with st.spinner("ë„êµ¬ ì‹¤í–‰ ì¤‘..."):
#                         try:
#                             tool_msg = selected_tool.invoke(tool_call)
#                             st.session_state.messages.append(tool_msg)
#                         except Exception as e:
#                             st.error(f"ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜:{e}")
#             # ë„êµ¬ í˜¸ì¶œ í›„ ì¬ê·€ì ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
#             yield from get_ai_response(st.session_state["messages"])


#          # AIì˜ ìµœì¢… ì‘ë‹µì´ ìˆìœ¼ë©´ ì´ë¥¼ ì¶œë ¥
#         if gathered:
#             # gatheredê°€ ìµœì¢…ì ìœ¼ë¡œ AI ì‘ë‹µì„ í¬í•¨í•˜ê³  ìˆìœ¼ë©´ ì´ë¥¼ ì¶œë ¥
#             ai_response = gathered.get('content', '')  # AI ì‘ë‹µì˜ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ê¸°

#             if ai_response:
#                 # Streamlitì— AIì˜ ì‘ë‹µ ì¶œë ¥
#                 st.write(f"AI ì‘ë‹µ: {ai_response}")
#                 # í•„ìš”ì‹œ UIë¥¼ í†µí•´ 'ëŒ€í™”' í˜•ì‹ìœ¼ë¡œ ì‘ë‹µì„ ì¶”ê°€
#                 st.session_state.messages.append({"role": "ai", "content": ai_response})


#     except Exception as e:
#         st.error(f"âŒ invoke() í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")



