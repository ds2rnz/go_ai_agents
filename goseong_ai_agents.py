import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langchain.agents.middleware import LLMToolSelectorMiddleware
from langchain_core.tools import tool
from langchain.messages import HumanMessage, AIMessage, SystemMessage
import datetime
from langchain_community.tools import DuckDuckGoSearchResults
from langchain_community.utilities import DuckDuckGoSearchAPIWrapper
from dotenv import load_dotenv
import os



load_dotenv()
api_key = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY"))

# -------------------------------
# 2ï¸âƒ£ LLM ì„¤ì •
# -------------------------------
llm = ChatOpenAI(
    model="gpt-4o-mini",  # ë˜ëŠ” "gpt-4o"
    temperature=0.4,
    api_key=api_key,
)

# -------------------------------
# 3ï¸âƒ£ DuckDuckGo ê²€ìƒ‰ Tool ì •ì˜
# -------------------------------
@tool
def web_search(query: str) -> str:
    """
    DuckDuckGo ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
    Args:
        query (str): ê²€ìƒ‰ì–´
    Returns:
        str: ê²€ìƒ‰ ê²°ê³¼ í…ìŠ¤íŠ¸ ìš”ì•½
    """
    wrapper = DuckDuckGoSearchAPIWrapper(max_results=5)
    search = DuckDuckGoSearchResults(api_wrapper=wrapper)
    results = search.run(query)
    return results

# ì‚¬ìš©í•  ë„êµ¬ ëª©ë¡
tools = [web_search]

# -------------------------------
# 4ï¸âƒ£ Agent ìƒì„±
# -------------------------------
agent = create_agent(
    model=llm,
    tools=tools
)

# -------------------------------
# 5ï¸âƒ£ Streamlit UI
# -------------------------------
st.set_page_config(page_title="LangChain Web Search Chatbot", page_icon="ğŸŒ")
st.title("ğŸŒ LangChain + DuckDuckGo Chatbot")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        SystemMessage(content="ì €ëŠ” ê³ ì„±êµ°ì²­ ì§ì›ì„ ìœ„í•´ ì¼í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. í•„ìš”í•œ ì •ë³´ë¥¼ ì‹ ì†í•˜ê²Œ ì°¾ì•„ë“œë¦¬ê² ìŠµë‹ˆë‹¤."),
        AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š"),
    ]

# ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for msg in st.session_state["messages"]:
    role = (
        "assistant" if isinstance(msg, AIMessage)
        else "user" if isinstance(msg, HumanMessage)
        else "system"
    )
    st.chat_message(role).write(msg.content)

# -------------------------------
# 6ï¸âƒ£ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
# -------------------------------
if prompt := st.chat_input("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ë° í‘œì‹œ
    st.chat_message("user").write(prompt)
    st.session_state["messages"].append(HumanMessage(content=prompt))
    inputs = {"messages": [{"role": "user", "content": prompt}]}
    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
    with st.chat_message("assistant"):
        stream_area = st.empty()
        streamed_text = ""

        # agent.stream()ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ì¶œë ¥
        for event in agent.stream(inputs, stream_mode="updates"):
            st.write(event.items())
            event_text = {event["messages"][-1].content_blocks}
            st.write(event_text)
            st.write("\n")
        #     if event_text.content:
        #         msg = event["messages"][-1]
        #         if isinstance(msg, AIMessage):
        #             streamed_text += msg.content
        #             stream_area.markdown(streamed_text + "â–Œ")

        # # ìµœì¢… ë‹µë³€ ì¶œë ¥
        # stream_area.markdown(streamed_text)
        # st.session_state["messages"].append(AIMessage(content=streamed_text))

# graph = create_agent(
#     model=llm,
#     tools=[check_weather],
#     system_prompt="You are a helpful assistant",
# )
# inputs = {"messages": [{"role": "user", "content": "what is the weather in sf"}]}
# for chunk in graph.stream(inputs, stream_mode="values"):
#     latest_message = chunk["messages"][-1]
#     if latest_message.content:
#         print(f"Agent: {latest_message.content}")
#     elif latest_message.tool_calls:
#         print(f"Calling tools: {[tc['name'] for tc in latest_message.tool_calls]}")