import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.tools import tool
from langchain.chat_models import init_chat_model
from langchain.agents import create_agent
from datetime import datetime
from langchain_community.tools.ddg_search import DuckDuckGoSearchRun
import pytz
from langchain_community.tools import DuckDuckGoSearchResults
from langchain_community.utilities import DuckDuckGoSearchAPIWrapper
from dotenv import load_dotenv
import os
from langchain.messages import HumanMessage, ToolMessage, SystemMessage, AIMessage
from langgraph.checkpoint.memory import InMemorySaver
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
from langchain_classic.chains import RetrievalQA
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
from pathlib import Path
import tempfile
import traceback
import time
from users_db import USERS_DB


def check_login(user_id, name):
    if user_id in USERS_DB:
        user_info = USERS_DB[user_id]
        if user_info.get("name") == name:
            return True, user_info
    return False, None


def show_login_page():
    """ë¡œê·¸ì¸ í˜ì´ì§€ í‘œì‹œ"""

    st.title("ğŸ” ë¡œê·¸ì¸")
    
    # ì¤‘ì•™ ì •ë ¬ì„ ìœ„í•œ ì»¬ëŸ¼
    col1, col2, col3 = st.columns([1, 1, 1])

    with col2:
  
        with st.form("login_form"):
            user_id = st.text_input("ì•„ì´ë””", placeholder="ìƒˆì˜¬ì•„ì´ë””ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            name = st.text_input("ì‚¬ìš©ìì´ë¦„",  placeholder="ì‚¬ìš©ì ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”")
            
            submit = st.form_submit_button("ë¡œê·¸ì¸", use_container_width=True)
            
            if submit:
                if user_id and name:
                    is_valid, user_info = check_login(user_id, name)
                    
                    if is_valid:
                        with st.spinner("ë¡œê·¸ì¸ ì¤‘..."):
                            time.sleep(1)
                        
                        st.session_state.logged_in = True
                        st.session_state.user_info = user_info
                        st.success(f"í™˜ì˜í•©ë‹ˆë‹¤, {user_info['name']}ë‹˜!")
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error("âŒ ë¡œê·¸ì¸ ID ë˜ëŠ” ì‚¬ìš©ìì´ë¦„ì„ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                else:
                    st.warning("âš ï¸ ë¡œê·¸ì¸ ID ë˜ëŠ” ì‚¬ìš©ìì´ë¦„ì„ ëª¨ë“  ì…ë ¥í•´ì£¼ì„¸ìš”.")

        st.markdown('</div>', unsafe_allow_html=True)

        # í•˜ë‹¨ ì •ë³´
        st.markdown("""
            <div style="text-align: center; margin-top: 3rem; color: #64748b;">
                <p>Made by ğŸ” ì´ë¬´í–‰ì •ê´€ ì •ë³´ê´€ë¦¬íŒ€</p>
                <p>v1.0.0 | 2025</p>
            </div>
        """, unsafe_allow_html=True)
       
        # ê³„ì • ì•ˆë‚´
        with st.expander("ğŸ“ ì‚¬ìš©ì ê³„ì • ì…ë ¥ë°©ë²•"):
            st.info("""
            **ì‚¬ìš©ì ê³„ì •:**
            - ì•„ì´ë””: user12345  / ìƒˆì˜¬ ë¡œê·¸ì¸ ID ì…ë ¥
            - ì‚¬ìš©ìì´ë¦„: í™ê¸¸ë™  /  ìƒˆì˜¬ ID ì‚¬ìš©ìëª…

            """)



# ==================== ê¸°ì¡´ í•¨ìˆ˜ë“¤ ====================
@tool
def get_current_time(timezone: str, location: str) -> str:
    '''  í•´ë‹¹ ì§€ì—­ í˜„ì¬ì‹œê°ì„ êµ¬í•˜ëŠ” í•¨ìˆ˜ '''
    try:
        tz = pytz.timezone(timezone)
        now = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")
        result = f'{timezone} ({location}) í˜„ì¬ì‹œê° {now}'
        return result
    except pytz.UnknownTimeZoneError:
        return f"ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì„ì¡´: {timezone}"  

@tool
def get_web_search(query: str) -> str:
    """
    ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜.

    Args:
        query (str): ê²€ìƒ‰ì–´
    Returns:
        str: ê²€ìƒ‰ ê²°ê³¼
    """
    custom_wrapper = DuckDuckGoSearchAPIWrapper(region="kr-kr", time="y", max_results=10)
    search = DuckDuckGoSearchResults(
        api_wrapper=custom_wrapper,
        source="news, image, text",
        results_separator=';\n')
    
    results = search.run(query)

    st.toast("ì›¹ ê²€ìƒ‰ì„ í†µì•„ì—¬ ì•Œì•„ë³´ê³  ìˆìŠµë‹ˆë‹¤.", icon="ğŸ‰")
    return results

    

def load_vectorstore(embedding, persist_directory="C:/faiss_store"):
    
    # ì €ì¥ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if not os.path.isdir(persist_directory):
        return None
        
    index_file = os.path.join(persist_directory, "index.faiss")
    pkl_file = os.path.join(persist_directory, "index.pkl")
    

    if os.path.exists(index_file) and os.path.exists(pkl_file):
        try:
            st.spinner("ğŸ“‚ ê¸°ì¡´ í•™ìŠµí•œ ìë£Œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
            vectorstore = FAISS.load_local(
                persist_directory, 
                embedding,
                allow_dangerous_deserialization=True
            )
            st.toast("ê¸°ì¡´ í•™ìŠµ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤!", icon="ğŸ“š")
            return vectorstore
        except Exception as e:
            st.warning(f"âš ï¸ ê¸°ì¡´ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    else:
        return None        


def answer_question(query: str):
    st.write("ğŸš€ ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘")
    vectorstore = st.session_state.get("vectorstore")
    if vectorstore is None:
        st.warning("âš ï¸ PDF í•™ìŠµì´ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return "ë¨¼ì € PDF ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  í•™ìŠµì‹œì¼œ ì£¼ì„¸ìš”."

    st.write("âœ… vectorstore í™•ì¸ ì™„ë£Œ")
    try:
        docs_with_scores = vectorstore.similarity_search_with_score(query, k=3)
        for i, (doc, score) in enumerate(docs_with_scores, 1):
            st.write(f"  ë¬¸ì„œ {i} ìœ ì‚¬ë„: {score:.4f}")

        SIMILARITY_THRESHOLD = 1.1
        relevant_docs = [doc for doc, score in docs_with_scores if score < SIMILARITY_THRESHOLD]
        if not relevant_docs:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        template = """ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
    
                    ë¬¸ì„œ ë‚´ìš©:
                    {context}

                    ì§ˆë¬¸: {question}

                    ë‹µë³€ ì‹œ ë‹¤ìŒì„ ì§€ì¼œì£¼ì„¸ìš”:
                    1. ë¬¸ì„œ ë‚´ìš©ì— ê¸°ë°˜í•˜ì—¬ ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
                    2. ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ì´ê³  ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
                    3. í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

                    ë‹µë³€:"""

        prompt = PromptTemplate(
                template=template,
                input_variables=["context", "question"]
                )
        retriever = vectorstore.as_retriever(search_kwargs={"k":3})
        qa_chain = RetrievalQA.from_chain_type(
               llm=llm,
               chain_type="stuff",
               retriever=retriever,
               chain_type_kwargs={"prompt": prompt},
               return_source_documents=False
                )
        result = qa_chain.invoke({"query": query})
        if isinstance(result, dict):
            return result.get("result", "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            return str(result)
    except Exception as e:
        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.code(traceback.format_exc(), language="python")
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
                

def ai_answer(messages):
    response = agent.invoke(
    {"messages": messages},
        config=config,
        tool_choice='any'
        )
    return response


def process1_f(uploaded_files1):
    """PDF íŒŒì¼ì„ í•™ìŠµí•˜ì—¬ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±"""
    
    if uploaded_files1 and len(uploaded_files1) > 3:
        st.error("âŒ PDFëŠ” ìµœëŒ€ 3ê°œê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤!")
        st.warning("âš ï¸ PDFíŒŒì¼ì„ 3ê°œë§Œ ì„ íƒí•˜ì—¬ ì£¼ì„¸ìš”!")
        return None
    
    if not uploaded_files1:
        st.warning("âš ï¸ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return None

    try:
        with st.spinner("ğŸ“š PDF ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”"):
            all_splits = []
            
            for idx, uploaded_file in enumerate(uploaded_files1, 1):
                st.write(f"ğŸ“„ {idx}/{len(uploaded_files1)} íŒŒì¼ ì²˜ë¦¬ ì¤‘: {uploaded_file.name}")
                
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                    tmp_file.write(uploaded_file.read())
                    tmp_path = tmp_file.name

                try:
                    loader = PyPDFLoader(tmp_path)
                    data = loader.load()
                    
                    splitter = RecursiveCharacterTextSplitter(
                        chunk_size=300, 
                        chunk_overlap=50
                    )
                    splits = splitter.split_documents(data)
                    all_splits.extend(splits)
                    
                    st.success(f"âœ… {uploaded_file.name}: {len(splits)}ê°œ ë¬¸ì„œë¡œ ë¶„í• ")
                    
                finally:
                    if os.path.exists(tmp_path):
                        os.remove(tmp_path)

            st.info(f"ğŸ“Š ì´ ë¬¸ì„œ ë¶„í•  ìˆ˜: {len(all_splits)}")

            embedding = OpenAIEmbeddings(
                model="text-embedding-3-large", 
                api_key=st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY"))
            )
            
            persist_directory = "C:/faiss_store"
            try:
                os.makedirs(persist_directory, exist_ok=True)
            except Exception as e:
                st.error(f"âŒ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
                return None

            batch_size = 20
            vectorstore = None
            total_batches = (len(all_splits) + batch_size - 1) // batch_size
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i in range(0, len(all_splits), batch_size):
                batch = all_splits[i:i+batch_size]
                batch_num = i//batch_size + 1
                
                status_text.text(f"ğŸ”„ ë°°ì¹˜ {batch_num}/{total_batches} í•™ìŠµìë£Œ ì €ì¥ ì¤‘...")
                progress_bar.progress(batch_num / total_batches)
                
                try:
                    if vectorstore is None:
                        vectorstore = FAISS.from_documents(batch, embedding)
                    else:
                        vectorstore.add_documents(batch)
                    
                    vectorstore.save_local(persist_directory)
                    time.sleep(1.5)
                    
                except Exception as e:
                    st.error(f"âŒ ë°°ì¹˜ {batch_num} í•™ìŠµìë£Œ ì €ì¥ ì‹¤íŒ¨: {e}")
                    continue
            
            progress_bar.progress(1.0)
            status_text.text("âœ… í•™ìŠµìë£Œ ì €ì¥ ì™„ë£Œ!")
            st.success("ğŸ‰ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.toast("í•™ìŠµí•œ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸í•´ ë³´ì„¸ìš”!", icon="ğŸ‰")
            
            return vectorstore
    except Exception as e:
        st.error(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.code(traceback.format_exc(), language="python")
        return None


# ==================== ë©”ì¸ ì•± í•¨ìˆ˜ ====================
def show_main_app():
    """ë©”ì¸ AI ë„ìš°ë¯¸ ì•±"""
    
    # í˜ì´ì§€ ì„¤ì •
    st.markdown("""
        <style>
            .centered-title {
                text-align: center;
                font-size: 3rem;
                color: #1e293b;
                margin-top: 0px;
                margin-bottom: 3px;
            }
            .ai-text {
                font-size: 3.5rem;
                color: #2563eb;
                margin-left: 10px;
                margin-right: 10px;
            }
        </style> 
        <h1 style="text-align: center; font-size: 3rem; color: #1e293b;">
        ğŸ’¬ ê³ ì„±êµ°ì²­ <span class="ai-text">AI</span> ë„ìš°ë¯¸ </h1>
    """, unsafe_allow_html=True)

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        # ì‚¬ìš©ì ì •ë³´ í‘œì‹œ
        st.markdown(f"""
            <div style="background: #e0f2fe; padding: 1rem; border-radius: 8px; margin-bottom: 1rem;">
                <p style="margin: 0; font-weight: bold; color: #0c4a6e;">ğŸ‘¤ {st.session_state.user_info['name']}</p>
                <p style="margin: 0.5rem 0 0 0; font-size: 0.85rem; color: #075985;">ID: {st.session_state.user_info['login_id']}</p>
            </div>
        """, unsafe_allow_html=True)
        
        # ë¡œê·¸ì•„ì›ƒ ë²„íŠ¼
        if st.button("ğŸšª ë¡œê·¸ì•„ì›ƒ", type="secondary", use_container_width=True):
            st.session_state.logged_in = False
            st.session_state.user_info = None
            st.rerun()
        
        st.markdown("---")
        
        # ë¬¸ì„œ í•™ìŠµê¸°
        st.markdown('<div class="sidebar-box">', unsafe_allow_html=True)
        
        st.markdown("""
            <h2 style="text-align: center; font-size: 1.7rem; color: #000000;">ğŸ“š ë¬¸ì„œ í•™ìŠµê¸°</h2>
            """, unsafe_allow_html=True)

        st.markdown("""
            <p class="upload-label">
                ğŸ“ PDF íŒŒì¼ ì—…ë¡œë“œ 
                <span class="badge">ìµœëŒ€ 3ê°œ</span>
            </p>
        """, unsafe_allow_html=True)
        
        uploaded_files1 = st.file_uploader(
            "í•™ìŠµí•  PDF ì„ íƒ",
            type=['pdf'],
            accept_multiple_files=True,
            key="uploader1",
            label_visibility="collapsed"
        )
        
        if uploaded_files1:
            st.markdown("""
                <div style="background: #f0fdf4; padding: 0.5rem; border-radius: 8px; margin-top: 0.5rem;">
                    <p style="margin: 0; font-size: 0.85rem; color: #15803d; font-weight: 500;">
                        âœ… {}ê°œ íŒŒì¼ ì„ íƒë¨
                    </p>
                </div>
            """.format(len(uploaded_files1)), unsafe_allow_html=True)
            
            for i, file in enumerate(uploaded_files1[:3], 1):
                st.markdown(f"""
                    <div style="font-size: 0.8rem; color: #475569; padding: 0.2rem 0.5rem;">
                        {i}. {file.name[:30]}{'...' if len(file.name) > 30 else ''}
                    </div>
                """, unsafe_allow_html=True)
        
        process1 = st.button(
            "ğŸš€ í•™ìŠµ ì‹œì‘",
            key="process1",
            type="primary",
            use_container_width=True
        )
        
        st.markdown("---")
        st.markdown("### ğŸ“– :blue[ì‚¬ìš©ë°©ë²•]")
        st.markdown("""
            1. PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”(ìµœëŒ€ 3ê°œë§Œ)
            2. "í•™ìŠµì‹œì‘" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
            3. í•™ìŠµí•œ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ë‹µë³€í•©ë‹ˆë‹¤.
            """)
            
        st.markdown("---")

        st.markdown("""
            <div style="text-align: center; padding: 1rem; color: #000000; font-size: 0.9rem;">
                <p style="margin: 0;">Made by ğŸ” ì´ë¬´í–‰ì •ê´€ ì •ë³´ê´€ë¦¬íŒ€</p>
                <p style="margin: 0.5rem 0 0 0;">v1.0.0 | 2025</p>
            </div>
        """, unsafe_allow_html=True)

    # ë©”ì‹œì§€ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "system", "content": "ì €ëŠ” ê³ ì„±êµ°ì²­ ì§ì›ì„ ìœ„í•´ ìµœì„ ì„ ë‹¤í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
            {"role": "assistant", "content": "ë¬´ì—‡ì´ì„ ë„ì™€ ë“œë¦´ê¹Œìš”?"}
        ]

    # ë©”ì‹œì§€ ì¶œë ¥
    for msg in st.session_state.messages:
        role = msg["role"]
        content = msg["content"]
        st.chat_message(role).write(content)

    # vectorstore ë¡œë“œ
    if "vectorstore" not in st.session_state:
        st.session_state["vectorstore"] = load_vectorstore(
            embedding=embedding,
            persist_directory="C:/faiss_store"
        )

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input(placeholder="ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)
        
        vectorstore = st.session_state.get("vectorstore")

        if vectorstore is not None:
            with st.spinner("ğŸ“š í•™ìŠµëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘..."):
                answer = answer_question(prompt)

            if answer and "ì£„ì†¡í•©ë‹ˆë‹¤. " in answer or len(answer) < 30:
                st.info("ğŸ’¡ í•™ìŠµëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¼ë°˜ AI ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    try:
                        response = ai_answer(st.session_state.messages)
                        ai_response = response['messages'][-1].content
                        st.toast("ì¼ë°˜ AI ëª¨ë“œë¡œ ë‹µë³€í•©ë‹ˆë‹¤....!", icon="ğŸ‰")
                        
                        st.session_state.messages.append({"role": "assistant", "content": ai_response})
                        st.chat_message("assistant").write(ai_response)
                    except Exception as e:
                        error_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                        st.session_state.messages.append({"role": "assistant", "content": error_msg})
                        st.chat_message("assistant").write(error_msg)
            else:
                st.session_state.messages.append({"role": "assistant", "content": answer})
                st.chat_message("assistant").write(answer)
        else:
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                try:
                    response = ai_answer(st.session_state.messages)
                    ai_response = response['messages'][-1].content
                    st.toast("ì¼ë°˜ AI ëª¨ë“œë¡œ ë‹µë³€í•©ë‹ˆë‹¤....!", icon="ğŸ‰")
                    
                    st.session_state.messages.append({"role": "assistant", "content": ai_response})
                    st.chat_message("assistant").write(ai_response)
                except Exception as e:
                    error_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})
                    st.chat_message("assistant").write(error_msg)

    # ë¬¸ì„œ í•™ìŠµ ì²˜ë¦¬
    if process1:
        st.session_state["vectorstore"] = process1_f(uploaded_files1)


# ==================== ë©”ì¸ ì‹¤í–‰ ====================
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

config = {"configurable": {"thread_id": "1"}}

llm = init_chat_model(
    model = "openai:gpt-4o",
    temperature=0.6, 
    max_tokens=1000, 
    timeout=10, 
    max_retries=2, 
    )

embedding = OpenAIEmbeddings(
    model="text-embedding-3-large", 
    api_key=st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY"))
    )

agent = create_agent(
    model=llm,
    tools=[get_current_time, get_web_search],
    middleware=[],
    system_prompt="ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„í•˜ë©´ êµ¬ì²´ì ì´ê³  ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ê³  ëª¨ë¥´ëŠ” ë‚´ìš©ì´ë©´ ì¸í„°ë„· ê²€ìƒ‰ì„ ê¼­í•´ì„œ ë‹µë³€í•´ì¤˜ ê·¸ë¦¬ê³  í•œê¸€ë¡œ ë‹µí•´ì£¼ì„¸ìš”", 
    )

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="GPT ê¸°ë°˜ AI ë„ìš°ë¯¸", page_icon="ğŸ’¬", layout="wide")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'logged_in' not in st.session_state:
    st.session_state.logged_in = False
if 'user_info' not in st.session_state:
    st.session_state.user_info = None

# ë¡œê·¸ì¸ ìƒíƒœì— ë”°ë¼ í˜ì´ì§€ í‘œì‹œ
if not st.session_state.logged_in:
    show_login_page()
else:
    show_main_app()
